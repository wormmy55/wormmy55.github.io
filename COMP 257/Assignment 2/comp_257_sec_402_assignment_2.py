# -*- coding: utf-8 -*-
"""COMP 257 SEC 402 - Assignment 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mUt7oSzbcdgkXEeyA4waH0H1pqtpvKdi

##Assignment 1
Name: Jonathan Au <br>
Student #: 300827701 <br>

#Question 1
1.	Retrieve and load the Olivetti faces dataset [5 points]
2.	Split the training set, a validation set, and a test set using stratified sampling to ensure that there are the same number of images per person in each set. Provide your rationale for the split ratio [10 points]
3.	Using k-fold cross validation, train a classifier to predict which person is represented in each picture, and evaluate it on the validation set. [15 points]
4.	Use K-Means to reduce the dimensionality of the set. Provide your rationale for the similarity measure used to perform the clustering. Use the silhouette score approach to choose the number of clusters. [20 points]
5.	Use the set from step (4) to train a classifier as in step (3) [20 points]
6.	Apply DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm to the Olivetti Faces dataset for clustering. Preprocess the images and convert them into feature vectors, then use DBSCAN to group similar images together based on their density. Provide your rationale for the similarity measure used to perform the clustering, considering the nature of facial image data. [30 points]
"""

#Imports
import math
import numpy as np
import pandas as pd
import matplotlib.cm as cm
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from scipy.spatial.distance import cdist
from sklearn.cluster import DBSCAN, KMeans
from sklearn.metrics import silhouette_score
from sklearn.metrics import silhouette_samples
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_olivetti_faces
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split, KFold

import warnings
warnings.filterwarnings("ignore")

"""1.	Retrieve and load the Olivetti faces dataset [5 points]"""

# Load olivetti faces
olivetti = fetch_olivetti_faces()
X = olivetti.data
Y = olivetti.target
Z = olivetti.images

# Print the description and shapes of the dataset
#print(olivetti.DESCR)
print(X.shape)
print(Y.shape)
print(Z.shape)

"""2.	Split the training set, a validation set, and a test set using stratified sampling to ensure that there are the same number of images per person in each set. Provide your rationale for the split ratio [10 points]"""

#split into train and test data
X_train, X_val_test, y_train, y_val_test = train_test_split(X, Y, test_size=.665)
#X_train, X_val_test, y_train, y_val_test = train_test_split(X, Y, test_size=.4)
#A test size of .665 was given such that the train data would be slightly larger as it was impossible for all three of them to be completly equal

#split train data into train and validation data
X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5)

#print the shapes of the data
print(X_train.shape)
print(X_test.shape)
print(X_val.shape)

"""3.	Using k-fold cross validation, train a classifier to predict which person is represented in each picture, and evaluate it on the validation set. [15 points]"""

#Use K-fold for cross val
kFoldCV = KFold(n_splits=5)
kFoldCV.get_n_splits(X)
print(kFoldCV)

#Training classifier for prediction

#y_pred = cross_val_predict(kmean, X_train, y_train, cv=kFoldCV)
y_pred = cross_val_predict(LogisticRegression(), X_train, y_train, cv=kFoldCV)
#y_pred = cross_val_predict(RandomForestRegressor(), X_train, y_train, cv=kFoldCV)
print("Y Prediction: ", y_pred)
#print("Accuracy Score: ", accuracy_score(y_train, y_pred))
#print("Confusion Matrix: ", confusion_matrix(y_train, y_pred))

score = cross_val_score(LogisticRegression(), X_train, y_train, cv=kFoldCV)
#score = cross_val_score(RandomForestRegressor(), X_train, y_train, cv=kFoldCV)
print("Score: ", score)

#Print K-fold cross val
#for i, (train, test) in kFoldCV.split(X):
#  print(f"Fold {i}:")
#  print("TRAIN:", train)
#  print("TEST:", test)

"""4.	Use K-Means to reduce the dimensionality of the set. Provide your rationale for the similarity measure used to perform the clustering. Use the silhouette score approach to choose the number of clusters. [20 points]"""

kmean = KMeans(n_clusters=3)
kmean.fit(X)

range_n_clusters = [2, 3, 4, 5, 6]
for n_clusters in range_n_clusters:
  #Use Silhouette score to choose cluster numbers
  clusterer = KMeans(n_clusters=n_clusters)
  cluster_labels = clusterer.fit_predict(X)
  silhouette_avg = silhouette_score(X, cluster_labels)
  print("For n_clusters =", n_clusters, "The average silhouette_score is :", silhouette_avg)

  # Compute and graph the silhouette scores for each sample
  #Steps that would be run to display the plot graphs
  """
  fig, (ax1, ax2) = plt.subplots(1, 2)
  fig.set_size_inches(18, 7)
  ax1.set_xlim([-0.1, 1])
  ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])
  sample_silhouette_values = silhouette_samples(X, cluster_labels)
  y_lower = 10
  for i in range(n_clusters):
    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]
    ith_cluster_silhouette_values.sort()
    size_cluster_i = ith_cluster_silhouette_values.shape[0]
    y_upper = y_lower + size_cluster_i
    color = plt.cm.nipy_spectral(float(i) / n_clusters)
    ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)
    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
    y_lower = y_upper + 10

  ax1.set_title("The silhouette plot for the various clusters.")
  ax1.set_xlabel("The silhouette coefficient values")
  ax1.set_ylabel("Cluster label")

  ax1.axvline(x=silhouette_avg, color="red", linestyle="--")
  ax1.set_yticks([])
  ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])
  colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)
  ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7, c=colors, edgecolor='k')

  centers = clusterer.cluster_centers_
  ax2.scatter(centers[:, 0], centers[:, 1], marker='o', c="white", alpha=1, s=200, edgecolor='k')
  for i, c in enumerate(centers):
    ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor='k')

  ax2.set_title("The visualization of the clustered data.")
  ax2.set_xlabel("Feature space for the 1st feature")
  ax2.set_ylabel("Feature space for the 2nd feature")
  plt.suptitle(("Silhouette analysis for KMeans clustering on sample data with n_clusters = %d" % n_clusters), fontsize=14, fontweight='bold')
  plt.show()
"""

"""5.	Use the set from step (4) to train a classifier as in step (3) [20 points]"""

y_pred = cross_val_predict(kmean, X_train, y_train, cv=kFoldCV)
print("Y Prediction: ", y_pred)
print("Accuracy Score: ", accuracy_score(y_train, y_pred))
#print("Confusion Matrix: ", confusion_matrix(y_train, y_pred))
y_pred = cross_val_predict(RandomForestRegressor(), X_train, y_train, cv=kFoldCV)
print("Y Prediction: ", y_pred)
#print("Accuracy Score: ", accuracy_score(y_train, y_pred))
#print("Confusion Matrix: ", confusion_matrix(y_train, y_pred))

score = cross_val_score(RandomForestRegressor(), X_train, y_train, cv=kFoldCV)
print("Score: ", score)

"""6.	Apply DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm to the Olivetti Faces dataset for clustering. Preprocess the images and convert them into feature vectors, then use DBSCAN to group similar images together based on their density. Provide your rationale for the similarity measure used to perform the clustering, considering the nature of facial image data. [30 points]

"""

#Applying DBScan
dbscan = DBSCAN(eps=3, min_samples=2)
clusters = dbscan.fit(X)
#print feature clusters
print(clusters)
print(clusters.labels_)

#Plotting DBscan
plt.scatter(X[:,0], X[:,1], c=clusters.labels_)
plt.xlabel('X Feature')
plt.ylabel('Y Feature')
plt.title('DBSCAN Clustering')
plt.show()

"""7. A 5-minute video presentation is required as part of the submission to document the steps taken to obtain the results. Any submission without a demo video will result in a 75% penalty."""